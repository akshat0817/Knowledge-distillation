# ğŸ–¼ï¸ Image Sharpening using Knowledge Distillation

This project implements an image sharpening system using **Knowledge Distillation**, where a powerful pretrained **Restormer** model acts as a **teacher** and a lightweight **Residual UNet** model is trained as a **student** to sharpen blurred images efficiently. The aim is to produce sharper images with fewer computational resources while maintaining high quality.



## ğŸ” Problem Statement

Blurry images (due to camera shake, defocus, or motion) often lose essential high-frequency details like edges, textures, and fine patterns. Recovering these details is critical for medical imaging, surveillance, and consumer photography.

The goal of this project is:

- To train a **lightweight student model** (Residual UNet) to sharpen blurry images.
- To use **Knowledge Distillation (KD)** to guide the student using a **pretrained teacher model (Restormer)**.
- To evaluate the modelâ€™s performance using **SSIM (Structural Similarity Index)** and **PSNR (Peak Signal-to-Noise Ratio)**.



## ğŸ§  Knowledge Distillation Framework

Knowledge Distillation is used to transfer knowledge from a large model (teacher) to a smaller model (student).

### ğŸ“Œ Loss Function Used:

We combine two types of loss:

- **L1 Loss between student output and ground truth**
- **L1 Loss between student output and teacher (Restormer) output**

### Formula:
TotalLoss = Î± Ã— L1(Student, GroundTruth) + Î² Ã— L1(Student, TeacherOutput)


Where:
- Î± = 0.8
- Î² = 0.2



## ğŸ“ Dataset

- Source: Custom dataset uploaded on Kaggle
- Total: **1800 image pairs**
  - 900 original (sharp + blurred)
  - 900 additional cropped & blurred images
- Blur Type: **Gaussian Blur**, Ïƒ = 0.5
- Format: `.png`, paired image names (e.g. `001.png` in both folders)

### Folder Structure:
Blur2Sharp/
â”œâ”€â”€ blur_Image/ # Blurred images
â””â”€â”€ sharp_Image/ # Ground truth sharp images




## ğŸ§° Technologies Used

| Tool             | Purpose                         |
|---------------   |-------------------------------- |
| **Kaggle**       | Training & evaluation (GPU: T4) |
| **PyTorch**      | Deep learning framework         |
| **Restormer**    | Pretrained teacher model        |
| **OpenCV**       | Image loading & preprocessing   |
| **scikit-image** | SSIM & PSNR calculation         |




## ğŸ§  Models

### âœ… Teacher Model â€” Restormer
- Source: [https://github.com/swz30/Restormer](https://github.com/swz30/Restormer)
- Task: Motion Deblurring
- Checkpoint: `motion_deblurring.pth`
- Used for inference only (teacher guidance)

### âœ… Student Model â€” Residual UNet
- Architecture: UNet-like with residual blocks
- Trained using L1 + KD Loss
- Efficient, lightweight & fast to train



## ğŸ“Š Results

| Metric    | Value          |
|--------   |----------------|
| **SSIM**  | âœ… 98.72%     |
| **PSNR**  | âœ… 37.91 dB   |

- Training Time: ~10 minutes on Kaggle T4 GPU
- Epochs: 5
- Input Image Size: 256Ã—256 (resized for speed)


## ğŸ—‚ï¸ Project Structure
Image-Sharpening-KD/
â”œâ”€â”€ notebook/
â”‚ â””â”€â”€ image-sharpening-kd.ipynb
â”œâ”€â”€ checkpoints/
â”‚ â””â”€â”€ residual_unet_student.pth
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ residual_unet.py
â”‚ â””â”€â”€ restormer_loader.py
â”œâ”€â”€ utils/
â”‚ â””â”€â”€ metrics.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

## ğŸ› ï¸ How to Run

1. Clone the repo:

git clone https://github.com/Kundayadav18/Image-Sharpening-KD.git
cd Image-Sharpening-KD

pip install -r requirements.txt

2. Install dependencies:
pip install -r requirements.txt

3.Run the notebook
jupyter notebook notebook/image-sharpening-kd.ipynb

4.Load trained weights (optional):
from models.residual_unet import ResidualUNet
student = ResidualUNet().to(device)
student.load_state_dict(torch.load("checkpoints/residual_unet_student.pth"))
student.eval()






